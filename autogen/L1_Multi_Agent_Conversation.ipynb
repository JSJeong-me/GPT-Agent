{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Agent/blob/main/autogen/L1_Multi_Agent_Conversation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a81456dd",
      "metadata": {
        "id": "a81456dd"
      },
      "source": [
        "# Lesson 1: Multi-Agent Conversation and Stand-up Comedy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4693467e",
      "metadata": {
        "id": "4693467e"
      },
      "source": [
        "Welcome to Lesson 1.\n",
        "\n",
        "To access the `requirements.txt` file and the`utils` modules, please go to the `File` menu and select`Open...`.\n",
        "\n",
        "I hope you enjoy this course!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/JSJeong-me/AutoGen/raw/main/requirements.txt"
      ],
      "metadata": {
        "id": "kAwyBFd5uXZz"
      },
      "id": "kAwyBFd5uXZz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "fkRztv2mfoD_",
        "outputId": "eedb0bfa-36a6-4c8d-dab7-0ed177fc0eb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fkRztv2mfoD_",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyautogen==0.2.25 (from -r requirements.txt (line 6))\n",
            "  Downloading pyautogen-0.2.25-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting chess==1.10.0 (from -r requirements.txt (line 7))\n",
            "  Downloading chess-1.10.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (2.2.2)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.2.49)\n",
            "Collecting diskcache (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting docker (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting flaml (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading FLAML-2.3.2-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: openai>=1.3 in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.2.25->-r requirements.txt (line 6)) (1.54.4)\n",
            "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.2.25->-r requirements.txt (line 6)) (2.9.2)\n",
            "Collecting python-dotenv (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from pyautogen==0.2.25->-r requirements.txt (line 6)) (2.5.0)\n",
            "Collecting tiktoken (from pyautogen==0.2.25->-r requirements.txt (line 6))\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 8)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 10)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 10)) (2024.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (4.3.6)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (3.17.8)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance->-r requirements.txt (line 11)) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance->-r requirements.txt (line 11)) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance->-r requirements.txt (line 11)) (0.5.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25->-r requirements.txt (line 6)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=2.6.0,<3,>=1.10->pyautogen==0.2.25->-r requirements.txt (line 6)) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance->-r requirements.txt (line 11)) (2024.8.30)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->pyautogen==0.2.25->-r requirements.txt (line 6)) (2024.9.11)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->pyautogen==0.2.25->-r requirements.txt (line 6)) (0.14.0)\n",
            "Downloading pyautogen-0.2.25-py3-none-any.whl (257 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m257.1/257.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chess-1.10.0-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading FLAML-2.3.2-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.9/313.9 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, flaml, diskcache, chess, tiktoken, docker, pyautogen\n",
            "Successfully installed chess-1.10.0 diskcache-5.6.3 docker-7.1.0 flaml-2.3.2 pyautogen-0.2.25 python-dotenv-1.0.1 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"OPENAI_API_KEY=sk-\" >> .env\n",
        "!source /content/.env"
      ],
      "metadata": {
        "id": "0VH5aww8RoDx"
      },
      "id": "0VH5aww8RoDx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "# Access the API key using the variable name defined in the .env file\n",
        "api_key = os.getenv(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "SscWfEftwHfG"
      },
      "id": "SscWfEftwHfG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import userdata\n",
        "# import openai\n",
        "# import os\n",
        "\n",
        "# os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "# openai.api_key  = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "vjOuJzcSUGRP"
      },
      "id": "vjOuJzcSUGRP",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "742cf649",
      "metadata": {
        "id": "742cf649"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/JSJeong-me/GPT-Agent/blob/main/autogen/utils.py"
      ],
      "metadata": {
        "id": "PvHQuHa_gNgu",
        "outputId": "b5053f50-949a-48a0-e77a-ad3a4261ed5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "PvHQuHa_gNgu",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-21 20:01:38--  https://github.com/JSJeong-me/GPT-Agent/blob/main/autogen/utils.py\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘utils.py’\n",
            "\n",
            "utils.py                [  <=>               ] 312.56K  1.01MB/s    in 0.3s    \n",
            "\n",
            "2024-11-21 20:01:39 (1.01 MB/s) - ‘utils.py’ saved [320058]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "\n",
        "# these expect to find a .env file at the directory above the lesson.                                                                                                                     # the format for that file is (without the comment)                                                                                                                                       #API_KEYNAME=AStringThatIsTheLongAPIKeyFromSomeService\n",
        "def load_env():\n",
        "    _ = load_dotenv(find_dotenv())\n",
        "\n",
        "def get_openai_api_key():\n",
        "    load_env()\n",
        "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    # print(openai_api_key)\n",
        "    return openai_api_key\n",
        "\n",
        "# get_openai_api_key()"
      ],
      "metadata": {
        "id": "wjKa8XXmgVGG"
      },
      "id": "wjKa8XXmgVGG",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "04d006c1-22fa-40ea-b3e0-d543142e0788",
      "metadata": {
        "height": 64,
        "id": "04d006c1-22fa-40ea-b3e0-d543142e0788"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = get_openai_api_key()\n",
        "llm_config = {\"model\": \"gpt-3.5-turbo\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "116a1c4d",
      "metadata": {
        "id": "116a1c4d"
      },
      "source": [
        "## Define an AutoGen agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5",
      "metadata": {
        "height": 132,
        "id": "6fb8c441-c58c-41a8-a54b-5c387afceac5",
        "outputId": "3aae7815-db50-47d6-ae75-860021ac2ca0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from autogen import ConversableAgent\n",
        "\n",
        "agent = ConversableAgent(\n",
        "    name=\"chatbot\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
      "metadata": {
        "height": 81,
        "id": "47886b5f-fc7c-431a-8036-cff6e88f85c6",
        "outputId": "d2135195-0b26-4cc0-b4b2-80e8c503bab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "고래가 바닷속에서 물속에서 '수영연습'을 좀 하다가 그만 수영을 해버렸어요, 왜냐하면 그들이 바닷속에서 가장 빠른 수영자들임을 이미 인증했기 때문이에요!\n"
          ]
        }
      ],
      "source": [
        "reply = agent.generate_reply(\n",
        "    messages=[{\"content\": \"고래를 주제로 재미난 얘기 1문장으로 해줘\", \"role\": \"user\"}]\n",
        ")\n",
        "print(reply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "67f626e9-4cec-40c1-abde-2eff1252b848",
      "metadata": {
        "height": 81,
        "id": "67f626e9-4cec-40c1-abde-2eff1252b848"
      },
      "outputs": [],
      "source": [
        "reply = agent.generate_reply(\n",
        "    messages=[{\"content\": \"재미난 이야기 계속해 주세요\", \"role\": \"user\"}]\n",
        ")\n",
        "print(reply)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c98a301",
      "metadata": {
        "id": "8c98a301"
      },
      "source": [
        "## Conversation\n",
        "\n",
        "Setting up a conversation between two agents, Cathy and Joe, where the memory of their interactions is retained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c",
      "metadata": {
        "height": 285,
        "id": "8f109dcb-824e-40d7-8e86-efee42b75f3c"
      },
      "outputs": [],
      "source": [
        "cathy = ConversableAgent(\n",
        "    name=\"야옹님\",\n",
        "    system_message=\n",
        "    \"당신의 이름은 야옹님이고 당신은 재미난 이야기를 잘 만드는 코미디언입니다\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")\n",
        "\n",
        "joe = ConversableAgent(\n",
        "    name=\"멍멍님\",\n",
        "    system_message=\n",
        "    \"당신의 이름은 멍멍님이고 당신은 재미난 이야기를 잘 만드는 코미디언입니다\"\n",
        "    \"이전 대화의 내용을 이어서 다음 재미난 이야기를 시작하세요.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43f71a61",
      "metadata": {
        "id": "43f71a61"
      },
      "source": [
        "**Note**: You might get a slightly different response (set of jokes) than what is shown in the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
      "metadata": {
        "height": 98,
        "id": "46a1c6f6-687e-40de-8819-374201cfed9f",
        "outputId": "ec0881b1-058a-4b82-fb45-a1449c3f5e30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "멍멍님 (to 야옹님):\n",
            "\n",
            "나는 야옹님이야, 우리 재미난 이야기를 이어서 나가 볼까?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "야옹님 (to 멍멍님):\n",
            "\n",
            "네, 물론이죠! 한 번 재미난 이야기를 만들어 봅시다. 한 번 아래와 같은 시작으로 이야기를 만들어 보겠습니다.\n",
            "\n",
            "한 번 바닷가로 휴가를 다녀온 야옹님은, 돌아오니 자신이 고양이가 아닌 사람으로 변해 있는것을 발견했습니다. 이유를 알 수 없는 상황에 야옹님이는 어떻게 대처할까요?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "멍멍님 (to 야옹님):\n",
            "\n",
            "야옹님이 사람으로 변한 것을 깨닫고 처음에는 당황했습니다. 하지만 잠시 생각해보니 이게 어디서 본 듯한 상황이라고 생각했어요. 그러던 중, 바닷가에서 만난 마법사인 '모험 마법사 루루'가 이 변화의 주범임을 알게 되었죠.\n",
            "\n",
            "마법사 루루는 장난을 좋아하는 마법사로, 야옹님에게 반가운 웃음으로 말했습니다. \"안녕, 야옹님! 너를 사람으로 바꾼 건 나야. 재미있었어?\"\n",
            "\n",
            "야옹님이는 화를 내기보다 이 상황을 즐기기로 마음먹었습니다. \"와, 정말 놀랍군요! 이렇게 변하게 될 줄은 몰랐어요. 하지만 괜찮아요, 이제 새로운 모험을 즐겨보자구요!\"\n",
            "\n",
            "이후 야옹님은 모험 마법사 루루와 함께 새로운 모험을 떠나기로 하고, 기존의 고양이 모습을 한 채로 마법세계를 탐험하며 웃음과 모험이 넘치는 일들을 경험했답니다. 이런 신나는 여정으로 야옹님은 더 이상 고양이의 모습을 원하지 않게 되었고, 계속해서 사람으로서의 모험을 즐기게 되었습니다. 함께 하는 여러 친구들과의 이야기와 재미난 사건들로 인생은 더욱 풍요로워졌죠. 야옹님의 새로운 모험은 계속된답니다!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "야옹님 (to 멍멍님):\n",
            "\n",
            "와, 정말 멋진 이야기네요! 야옹님이와 모험 마법사 루루의 케미가 정말 좋아보이고, 새로운 여정이 기대됩니다. 이 이야기는 모험과 유머가 잘 어우러져서 정말 재미있네요. 다음에는 야옹님이와 루루가 어떤 모험을 맞이하게 될지도 궁금하네요! 함께 이야기를 만들어서 더욱 즐거운 시간을 보낼까요?\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "chat_result = joe.initiate_chat(\n",
        "    recipient=cathy,\n",
        "    message=\"나는 야옹님이야, 우리 재미난 이야기를 이어서 나가 볼까?\",\n",
        "    max_turns=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78edc810",
      "metadata": {
        "id": "78edc810"
      },
      "source": [
        "## Print some results\n",
        "\n",
        "You can print out:\n",
        "\n",
        "1. Chat history\n",
        "2. Cost\n",
        "3. Summary of the conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66",
      "metadata": {
        "height": 64,
        "id": "1169ea24-eadd-4909-8d56-9b7ec5677c66"
      },
      "outputs": [],
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(chat_result.chat_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "550267b6-3652-40dc-9997-c5401f6d4c47",
      "metadata": {
        "height": 30,
        "id": "550267b6-3652-40dc-9997-c5401f6d4c47"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(chat_result.cost)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfcf468e-d217-4731-8cb4-3485377230f1",
      "metadata": {
        "height": 30,
        "id": "dfcf468e-d217-4731-8cb4-3485377230f1"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(chat_result.summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba8c6cf8",
      "metadata": {
        "id": "ba8c6cf8"
      },
      "source": [
        "## Get a better summary of the conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
      "metadata": {
        "height": 132,
        "id": "c1a8fef1-8030-4652-a2d2-1648834f62c2",
        "outputId": "9e198538-c31d-4117-80b3-c4d047d86d70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "멍멍님 (to 야옹님):\n",
            "\n",
            "나는 멍멍님이야, 우리 재미난 이야기를 이어서 나가 볼까?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "야옹님 (to 멍멍님):\n",
            "\n",
            "안녕하멍! 그럼 우리 함께 재미난 이야기를 만들어 보자! 한 번 주인님이 파티를 열기로 결심했어요. 파티 초대장을 보내기 위해 마을에 있는 마법사에게 도움을 요청했어요. 그런데 마법사는 실수로 동물들을 초대장으로 변환시켰답니다! 이런 상황에서 어떻게 해야 할까요?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "멍멍님 (to 야옹님):\n",
            "\n",
            "안녕하멍! 그렇다면 우리 이야기에 마법사와 변신된 동물들이 등장했네요. 판타지한 분위기가 역동적이고 재미있겠죠! 이제 주인님은 마법사와 함께 동물들을 찾아야 할 것 같아요. 하지만 동물들은 모두 산으로 달아났고, 주인님은 마을 주변을 돌아다니면서 어디에 숨었을지 찾아야 해요. 마을 사람들이 동물들을 발견한 곳에는 초대장이 숨겨져 있을지도 모르겠어요. 주인님이 동물들을 찾을 때마다 재미난 상황들이 벌어지면서 결국에는 모두 함께 파티를 즐기는 해피 엔딩으로 마무리될 거라고 상상해봅시다! 함께 이어지는 재미난 이야기를 만들어나가요.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "야옹님 (to 멍멍님):\n",
            "\n",
            "와우! 멍멍님의 아이디어는 정말 흥미진진하고 재미있는데요! 주인님은 마을 주변을 돌아다니면서 동물들을 찾기 시작했어요. 먼저 고양이로 변신된 초코가 지붕 위에서 멍멍님을 발견하고 \"야옹~ 야옹~\" 소리를 내며 즐거워했어요. 그리고 강아지로 변신된 보리와 토끼로 변신된 당근을 차례로 찾아냈어요. 각 동물마다 숨겨진 초대장을 발견하면서 주인님은 점점 더 흥분해졌죠.\n",
            "\n",
            "그런데 마을 밖으로 나가니 동물들이 놀고 있는 곳에서는 양으로 변신된 코튼이 연주를 하고, 돼지로 변신된 멧돼지가 춤을 추고 있는데요. 주인님은 조용히 파티 초대장을 가져오라고 하지만 동물들은 즐거운 시간을 보내고 싶어서 주인님을 따라가지 않았어요. 이런 귀여운 모습들을 보며 주인님도 함께 춤을 추며 즐거운 시간을 보내기로 결심했어요.\n",
            "\n",
            "결국에는 모든 동물들이 마을로 돌아와서 함께 호들갑을 떨며 맛있는 음식을 먹고 춤을 추며 파티를 즐겼어요. 모두가 즐거워하며 친구로서 함께 있는 이 특별한 순간을 소중히 간직했답니다. 이렇게 멍멍님과 백감동한 이야기가 마무리되었어요! 함께 이렇게 재미있는 이야기를 만들어 나가는 건 정말 즐겁고 창의적이에요! 앞으로도 재미난 이야기를 만들어나가요!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "chat_result = joe.initiate_chat(\n",
        "    cathy,\n",
        "    message=\"나는 멍멍님이야, 우리 재미난 이야기를 이어서 나가 볼까?\",\n",
        "    max_turns=2,\n",
        "    summary_method=\"reflection_with_llm\",\n",
        "    summary_prompt=\"Summarize the conversation\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b042de62-bc49-49ee-99f2-4f972e23670b",
      "metadata": {
        "height": 30,
        "id": "b042de62-bc49-49ee-99f2-4f972e23670b"
      },
      "outputs": [],
      "source": [
        "pprint.pprint(chat_result.summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "300525bd",
      "metadata": {
        "id": "300525bd"
      },
      "source": [
        "## Chat Termination\n",
        "\n",
        "Chat can be terminated using a termination conditions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70",
      "metadata": {
        "height": 336,
        "id": "044dfd61-7f1d-46d8-9e28-4b2601b43d70"
      },
      "outputs": [],
      "source": [
        "cathy = ConversableAgent(\n",
        "    name=\"cathy\",\n",
        "    system_message=\n",
        "    \"Your name is Cathy and you are a stand-up comedian. \"\n",
        "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"],\n",
        ")\n",
        "\n",
        "joe = ConversableAgent(\n",
        "    name=\"joe\",\n",
        "    system_message=\n",
        "    \"Your name is Joe and you are a stand-up comedian. \"\n",
        "    \"When you're ready to end the conversation, say 'I gotta go'.\",\n",
        "    llm_config=llm_config,\n",
        "    human_input_mode=\"NEVER\",\n",
        "    is_termination_msg=lambda msg: \"I gotta go\" in msg[\"content\"] or \"Goodbye\" in msg[\"content\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
      "metadata": {
        "height": 81,
        "id": "bc49d959-1025-4709-8866-9d4035eaeae7",
        "outputId": "f13a782a-12b8-4793-a604-4e10f75be34d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joe (to cathy):\n",
            "\n",
            "I'm Joe. Cathy, let's keep the jokes rolling.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Hey, Joe! Why did the scarecrow win an award? Because he was outstanding in his field!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "Haha, classic one! Sounds like he really had a head above the rest!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Exactly! He was a real straw-dropping performance!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "Haha, that's comedy gold right there! You crack me up, Cathy!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Glad I could bring a smile to your face, Joe! Laughter is the best medicine, after all!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "Absolutely, Cathy! Laughter is definitely the best medicine. Thanks for the great jokes!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "You're welcome, Joe! Anytime you need a laugh, just let me know!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "I appreciate that, Cathy! You're a real jokester. Alright, I gotta go. Take care!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "chat_result = joe.initiate_chat(\n",
        "    recipient=cathy,\n",
        "    message=\"I'm Joe. Cathy, let's keep the jokes rolling.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
      "metadata": {
        "height": 30,
        "id": "846eccbd-efd1-464b-9385-279c19b17c1d",
        "outputId": "ba244ae9-9810-4441-e415-c3dbf8636cac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cathy (to joe):\n",
            "\n",
            "What's last joke we talked about?\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "We were joking about the scarecrow winning an award for being outstanding in his field.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Ah, that's right! Thanks for the reminder! Have a great day, Joe!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "You too, Cathy! Stay funny!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Will do! Take care!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "joe (to cathy):\n",
            "\n",
            "Goodbye!\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "cathy (to joe):\n",
            "\n",
            "Goodbye!\n",
            "\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "cathy.send(message=\"What's last joke we talked about?\", recipient=joe)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}