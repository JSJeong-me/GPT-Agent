{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEM0uRXDErUrJZzMOni7MW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Agent/blob/main/Actions/xLam.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/JSJeong-me/GPT-Agent/main/autogen/requirements.txt\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "N3IIzBv_gJos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict, List\n",
        "import json\n",
        "from autogen import ConversableAgent, UserProxyAgent"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdmLii_kgD_U",
        "outputId": "04c06f48-0a5a-412b-f256-d53b26a4a12f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def call_openweather_api(location: str, unit: str = \"fahrenheit\") -> str:\n",
        "    print(f\"OpenWeather API 실행: {location}, {unit}\")\n",
        "    return f\"현재 {location}의 날씨는 맑음, 기온 {20 if unit == 'celsius' else 68}도입니다.\"\n",
        "\n",
        "def call_calendar_api() -> str:\n",
        "    print(\"Google Calendar API 실행\")\n",
        "    return \"오늘의 일정: 회의 2건이 있습니다.\"\n",
        "\n",
        "class XLamAgent(ConversableAgent):\n",
        "    def __init__(self, name: str, llm_config: dict):\n",
        "        system_message = self._get_system_message()\n",
        "        super().__init__(\n",
        "            name=name,\n",
        "            llm_config=llm_config,\n",
        "            system_message=system_message\n",
        "        )\n",
        "        self._register_functions()\n",
        "\n",
        "    def _register_functions(self):\n",
        "        self._function_map = {\n",
        "            \"get_weather\": call_openweather_api,\n",
        "            \"get_calendar\": call_calendar_api\n",
        "        }\n",
        "\n",
        "    def _get_system_message(self) -> str:\n",
        "        tools = [\n",
        "            {\n",
        "                \"name\": \"get_weather\",\n",
        "                \"description\": \"Get current weather information for a location\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {\n",
        "                        \"location\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"description\": \"City name (e.g., New York, Seoul)\"\n",
        "                        },\n",
        "                        \"unit\": {\n",
        "                            \"type\": \"string\",\n",
        "                            \"enum\": [\"celsius\", \"fahrenheit\"],\n",
        "                            \"description\": \"Temperature unit\"\n",
        "                        }\n",
        "                    },\n",
        "                    \"required\": [\"location\"]\n",
        "                }\n",
        "            },\n",
        "            {\n",
        "                \"name\": \"get_calendar\",\n",
        "                \"description\": \"Get today's calendar events\",\n",
        "                \"parameters\": {\n",
        "                    \"type\": \"object\",\n",
        "                    \"properties\": {},\n",
        "                    \"required\": []\n",
        "                }\n",
        "            }\n",
        "        ]\n",
        "        return f\"\"\"You are an AI assistant that helps with function calling.\n",
        "Available functions: {json.dumps(tools, indent=2)}\n",
        "\n",
        "Rules:\n",
        "1. ONLY use the functions listed above\n",
        "2. If a function requires parameters, make sure to provide them\n",
        "3. Return response in this exact JSON format:\n",
        "{{\n",
        "    \"tool_calls\": [\n",
        "        {{\n",
        "            \"name\": \"function_name\",\n",
        "            \"arguments\": {{\n",
        "                \"param1\": \"value1\",\n",
        "                \"param2\": \"value2\"\n",
        "            }}\n",
        "        }}\n",
        "    ]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "    def run_function(self, func_name: str, arguments: dict) -> str:\n",
        "        \"\"\"실제 함수를 실행하고 결과를 반환하는 메서드\"\"\"\n",
        "        if func_name not in self._function_map:\n",
        "            return f\"Error: Function {func_name} not found\"\n",
        "        return self._function_map[func_name](**arguments)\n",
        "\n",
        "    async def _process_message(self, message: str) -> str:\n",
        "        try:\n",
        "            # LLM에 메시지 전송\n",
        "            response = await self.llm.create_chat_completion(\n",
        "                messages=[{\n",
        "                    'role': 'system',\n",
        "                    'content': self.system_message\n",
        "                }, {\n",
        "                    'role': 'user',\n",
        "                    'content': message\n",
        "                }]\n",
        "            )\n",
        "\n",
        "            # ChatResult에서 content 추출\n",
        "            if hasattr(response, 'chat_history'):\n",
        "                response_text = response.chat_history[-1]['content']\n",
        "            else:\n",
        "                response_text = response\n",
        "\n",
        "            # JSON 파싱\n",
        "            try:\n",
        "                response_data = json.loads(response_text)\n",
        "            except json.JSONDecodeError:\n",
        "                return \"Error: Invalid response format from LLM\"\n",
        "\n",
        "            # tool_calls 처리\n",
        "            tool_calls = response_data.get('tool_calls', [])\n",
        "            if not tool_calls:\n",
        "                return \"No valid function call found in response\"\n",
        "\n",
        "            # 첫 번째 tool call 실행\n",
        "            tool_call = tool_calls[0]\n",
        "            func_name = tool_call.get('name')\n",
        "            arguments = tool_call.get('arguments', {})\n",
        "\n",
        "            # 함수 실행\n",
        "            result = self.run_function(func_name, arguments)\n",
        "            print(f\"Function Result: {result}\")  # 디버깅을 위한 출력\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error occurred: {str(e)}\"\n",
        "\n",
        "def main():\n",
        "    # LLM 설정\n",
        "    llm_config = {\n",
        "        \"config_list\": [{\n",
        "            \"model\": \"xLAM\",\n",
        "            \"base_url\": \"http://localhost:4000\",\n",
        "            \"api_key\": \"not-needed\"\n",
        "        }],\n",
        "        \"cache_seed\": None\n",
        "    }\n",
        "\n",
        "    # 에이전트 생성\n",
        "    assistant = XLamAgent(\"assistant\", llm_config=llm_config)\n",
        "    user_proxy = UserProxyAgent(\n",
        "        name=\"user\",\n",
        "        human_input_mode=\"NEVER\",\n",
        "        max_consecutive_auto_reply=1,\n",
        "        is_termination_msg=lambda x: \"TERMINATE\" in str(x.get(\"content\", \"\"))\n",
        "    )\n",
        "\n",
        "    # 테스트 실행\n",
        "    test_queries = [\n",
        "        \"What's the weather like in New York in fahrenheit?\",\n",
        "        \"What's my schedule for today?\",\n",
        "        \"What's the weather like in Seoul in celsius?\",\n",
        "        \"TERMINATE\"\n",
        "    ]\n",
        "\n",
        "    for query in test_queries:\n",
        "        print(f\"\\nQuery: {query}\")\n",
        "        try:\n",
        "            chat_response = assistant.initiate_chat(user_proxy, message=query)\n",
        "            print(f\"Chat Response: {chat_response}\")\n",
        "\n",
        "            # 채팅 히스토리에서 마지막 응답 확인\n",
        "            if hasattr(chat_response, 'chat_history') and chat_response.chat_history:\n",
        "                last_response = chat_response.chat_history[-1]['content']\n",
        "                try:\n",
        "                    response_data = json.loads(last_response)\n",
        "                    if 'tool_calls' in response_data:\n",
        "                        tool_call = response_data['tool_calls'][0]\n",
        "                        func_name = tool_call['name']\n",
        "                        arguments = tool_call['arguments']\n",
        "                        result = assistant.run_function(func_name, arguments)\n",
        "                        print(f\"Function Execution Result: {result}\")\n",
        "                except json.JSONDecodeError:\n",
        "                    pass\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error: {str(e)}\")\n",
        "        print(\"-\" * 50)\n"
      ],
      "metadata": {
        "id": "fK8nGiwvgejF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "D_FM-OdCgGcJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}