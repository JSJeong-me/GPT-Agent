{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMmzaIc9pDuGdp0WoEgYBrF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JSJeong-me/GPT-Agent/blob/main/LangChain/00-Memory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -U langgraph langchain langchain_openai"
      ],
      "metadata": {
        "id": "rg7dZRHL9BkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "SeS9vaucWS4u"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.graph import START, MessagesState, StateGraph\n",
        "from langchain_openai import ChatOpenAI # Corrected import\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import openai\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
        "openai.api_key  = os.environ[\"OPENAI_API_KEY\"]"
      ],
      "metadata": {
        "id": "rPXEbGpG8Y84"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# 1) 상태 스키마 정의\n",
        "workflow = StateGraph(state_schema=MessagesState)\n",
        "\n",
        "# 2) 모델 호출 노드 정의: 이전 메시지 리스트 사용\n",
        "def call_model(state: MessagesState):\n",
        "    response = llm.invoke(state[\"messages\"])\n",
        "    return {\"messages\": response}\n",
        "\n",
        "workflow.add_edge(START, \"model\")\n",
        "workflow.add_node(\"model\", call_model)\n",
        "\n",
        "# 3) 메모리 저장소 (MemorySaver) 활용\n",
        "memory = MemorySaver()\n",
        "app = workflow.compile(checkpointer=memory)\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"user123\"}}\n",
        "\n",
        "# 첫 대화\n",
        "output = app.invoke({\"messages\": [HumanMessage(\"안녕!\") ]}, config)\n",
        "print(output[\"messages\"][-1])\n",
        "\n",
        "# 이어지는 대화\n",
        "output = app.invoke({\"messages\": [HumanMessage(\"내 이름이 뭐였지?\") ]}, config)\n",
        "print(output[\"messages\"][-1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQwmFtBi8a8J",
        "outputId": "601549d1-0ea3-4900-a72e-2b4ac51cd7e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='안녕하세요! 어떻게 도와드릴까요?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 10, 'total_tokens': 20, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CBrNJILE6d757edzUvsB3EDhn9Wq4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--1ce97f48-575d-4ec8-8da7-a1a475370bb1-0' usage_metadata={'input_tokens': 10, 'output_tokens': 10, 'total_tokens': 20, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "content='죄송하지만, 이전 대화 내용을 기억할 수 없어서 이름을 알 수 없습니다. 당신의 이름을 알려주시면 기억할 수 있을 것 같아요!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 35, 'total_tokens': 69, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_8bda4d3a2c', 'id': 'chatcmpl-CBrNLuSnlpduyPdRehCk6qtOKiEBZ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--8d81ac8f-8643-4187-8ee5-e1a233f2474a-0' usage_metadata={'input_tokens': 35, 'output_tokens': 34, 'total_tokens': 69, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이어지는 대화 with memory\n",
        "print(\"\\n--- 이어지는 대화 (메모리 사용) ---\")\n",
        "output = app.invoke({\"messages\": [HumanMessage(\"내 이름이 뭐였지?\")]}, config)\n",
        "print(output[\"messages\"][-1])\n",
        "\n",
        "# 메모리 확인 (optional)\n",
        "# thread_id = config[\"configurable\"][\"thread_id\"]\n",
        "# saved_messages = memory.get(thread_id)\n",
        "# print(\"\\n--- 저장된 메모리 확인 ---\")\n",
        "# print(saved_messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKz8OOzd9ISB",
        "outputId": "efcabbbf-65ad-4dcf-bdae-9a7c5a11cd08"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- 이어지는 대화 (메모리 사용) ---\n",
            "content='죄송하지만, 저는 이전의 대화 내용을 기억할 수 없어서 당신의 이름을 알 수 없습니다. 당신의 이름을 말씀해 주시면 그에 맞춰 이야기할 수 있을 거예요!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 84, 'total_tokens': 127, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CBrObnjbUntf7jHvm8JfOndMeKqIu', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--880f2206-982d-45a8-8ddb-785a2ae587c8-0' usage_metadata={'input_tokens': 84, 'output_tokens': 43, 'total_tokens': 127, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ]
    }
  ]
}